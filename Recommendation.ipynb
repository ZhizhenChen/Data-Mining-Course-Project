{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuHr3tSOfe8k",
        "outputId": "89d576e3-e4d7-4143-9dd1-27708fca1e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=611b9e4e5567f736df66bdf007afbe1f7fd3128fbb4c3d3a0f4d7e8feb6101a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jarEVGCAebjz"
      },
      "outputs": [],
      "source": [
        "# Let's import the libraries we will need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AQzTLS36fwcq"
      },
      "outputs": [],
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = SparkContext.getOrCreate(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Lo-J6UL7fxuy"
      },
      "outputs": [],
      "source": [
        "# read the data\n",
        "ori = spark.read.text(\"ego-facebook.txt\")\n",
        "\n",
        "value = []\n",
        "\n",
        "dfc = ori.collect()\n",
        "\n",
        "for row in dfc:\n",
        "  value.append((int(row[0].split(' ')[0]),int(row[0].split(' ')[1])))\n",
        "  value.append((int(row[0].split(' ')[1]),int(row[0].split(' ')[0])))\n",
        "\n",
        "# generate the dataframe\n",
        "df = spark.createDataFrame(value, ['id_1', 'id_2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bkcfGMbBoFgU"
      },
      "outputs": [],
      "source": [
        "# self left join and select three columns represent user, mutual friend and second degree friend\n",
        "df_join = df.alias(\"df1\").join(df.alias(\"df2\"),\n",
        "                               col(\"df1.id_2\") == col(\"df2.id_1\"),\"left\").select(col(\"df1.id_1\"),\n",
        "                              col(\"df2.id_1\").alias(\"join_1\"), \n",
        "                              col(\"df2.id_2\").alias(\"join_2\"))\n",
        "\n",
        "# drop the duplicate rows\n",
        "df_1 = df_join.filter(df_join.id_1 != df_join.join_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "moxgosypD0A9"
      },
      "outputs": [],
      "source": [
        "# group by user and second degree friend and count the mutual friend\n",
        "gf = df_1.groupby(['id_1','join_2']).agg(size(collect_set('join_1')).alias(\"mf_count\"))\n",
        "\n",
        "# set up the dataframe for keys who actually mutual friend\n",
        "sub = gf.alias('gd').join(df.alias('od'), (gf[\"id_1\"] == df[\"id_1\"]) \n",
        "                              & (gf[\"join_2\"] == df[\"id_2\"])).select(col('gd.id_1'),col('gd.join_2'),col('gd.mf_count'))\n",
        "\n",
        "# take subtraction\n",
        "gf = gf.subtract(sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TUjhNee0TAY4"
      },
      "outputs": [],
      "source": [
        "# sorting\n",
        "window = Window.partitionBy(\"id_1\").orderBy(col(\"mf_count\").desc(),col('join_2').asc())\n",
        "gf = gf.withColumn(\"second_friend\",collect_list(\"join_2\").over(window)).groupby(\"id_1\").agg(max('second_friend').alias(\"recommendation\"))\n",
        "gf = gf.orderBy(col('id_1').asc())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu7EZP-G_wBl",
        "outputId": "7e378fe8-7460-47c5-80e1-1822c6d43d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 \t [2, 3, 4, 5, 6, 7, 8, 9, 11, 12]\n",
            "152 \t [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "288 \t [71, 1525, 69, 90, 217, 2348, 2351, 2352, 2354, 2356]\n",
            "603 \t [1, 289, 290, 291, 292, 293, 294, 295, 296, 297]\n",
            "714 \t [1, 712, 713, 715, 717, 718, 1525, 90, 217, 247]\n",
            "1525 \t [288, 1, 710, 714, 603]\n",
            "2434 \t [71, 288, 711, 716, 719, 720, 2348, 2351, 2352, 2354]\n",
            "2681 \t [71, 288, 710, 711, 716, 719, 720, 721, 722, 2348]\n"
          ]
        }
      ],
      "source": [
        "check = [10,152,288,603,714,1525,2434,2681]\n",
        "\n",
        "for row in gf.collect():\n",
        "  if row.id_1 in check:\n",
        "    print(row.id_1,\"\\t\",row.recommendation[:10])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
